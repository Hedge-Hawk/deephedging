{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e9279e-55b6-407d-a439-8a7c007974c3",
   "metadata": {},
   "source": [
    "# Deep Hedging AI\n",
    "### Recurrent Network: impact of using recurrent networks on hedging barrier options. In this example, Deep Hedging does mot learn anything - which is superior to using Black & Scholes.\n",
    "\n",
    "Hans Buehler, January 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d4e96d5-7016-4d65-97f6-e95f21df85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Slighly annoying: by default the SageMaker Python import directory does not include our git directory \"\"\"\n",
    "#!pip -q install cdxbasics \"tensorflow>=2.10\" \"tensorflow_probability==0.14\"\n",
    "import os\n",
    "p = os.getcwd()\n",
    "dhn = \"/deephedging/\"\n",
    "i = p.find(dhn)\n",
    "if i!=-1:\n",
    "    p = p[:i]\n",
    "    import sys\n",
    "    sys.path.append(p)\n",
    "    print(\"SageMaker: added python path %s\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d077d5-186e-478e-ace4-0117216109bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Hedging AI says hello ... "
     ]
    }
   ],
   "source": [
    "print(\"Deep Hedging AI says hello ... \", end='')\n",
    "\n",
    "import importlib as imp\n",
    "import deephedging.agents as _\n",
    "imp.reload(_)\n",
    "\n",
    "from cdxbasics.config import Config\n",
    "from cdxbasics.prettydict import PrettyOrderedDict as pdct\n",
    "from deephedging.trainer import train\n",
    "from deephedging.gym import VanillaDeepHedgingGym\n",
    "from deephedging.world import SimpleWorld_Spot_ATM\n",
    "from cdxbasics.dynaplot import figure, colors_tableau\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# see print of the config below for numerous options\n",
    "config = Config()\n",
    "# world\n",
    "config.world.steps = 20*5\n",
    "config.world.dt    = 1./50./5.\n",
    "iReset = 10\n",
    "\n",
    "nBins = 200\n",
    "\n",
    "strike  = 1.\n",
    "barrier = 0.95\n",
    "def payoff_def( spots ):\n",
    "    notko      = np.cumprod( np.where( spots[:,:] > barrier, 1., 0. ), axis=1 )\n",
    "    terminal   = np.maximum( 1. - spots[:,-1], 0. )  # put\n",
    "    return dict( payoff=-terminal*notko[:,-1],\n",
    "                 features=notko[:,:-1] )\n",
    "payoff_def.name = \"KO Put k=%g, b=%g\" % (strike, barrier)\n",
    "\n",
    "config.world.samples = 20000\n",
    "config.world.drift = 0.\n",
    "config.world.cost_s = 0.\n",
    "config.world.black_scholes = True\n",
    "config.world.payoff = payoff_def\n",
    "# gym\n",
    "config.gym.objective.utility = \"exp\"\n",
    "config.gym.objective.lmbda = 1.01\n",
    "config.gym.agent.network.depth = 5\n",
    "config.gym.agent.network.width = 50\n",
    "config.gym.agent.network.activation = \"softplus\"\n",
    "config.gym.agent.recurrence.states.classic   = 1\n",
    "config.gym.agent.recurrence.states.aggregate = 1\n",
    "config.gym.agent.recurrence.states.past_repr = 1\n",
    "config.gym.agent.recurrence.states.event     = 1\n",
    "config.gym.agent.features = ['price', 'delta', 'time_left', 'payoff_features']\n",
    "#\n",
    "# trainer\n",
    "config.trainer.train.optimizer.name = \"adam\"\n",
    "config.trainer.train.optimizer.learning_rate = 0.001\n",
    "config.trainer.train.optimizer.clipvalue = 0.9\n",
    "config.trainer.train.optimizer.global_clipnorm = 1.\n",
    "config.trainer.train.batch_size = None\n",
    "config.trainer.train.epochs = 250\n",
    "config.trainer.caching.mode = \"on\"\n",
    "config.trainer.caching.epoch_freq = 100\n",
    "config.trainer.visual.epoch_refresh = 20\n",
    "config.trainer.visual.confidence_pcnt_lo = 0.25\n",
    "config.trainer.visual.confidence_pcnt_hi = 0.75\n",
    "config_ref = config.copy()  # create unused copy\n",
    "\n",
    "# create world\n",
    "world      = SimpleWorld_Spot_ATM( config.world )\n",
    "val_world  = world.clone(samples=world.nSamples//2)\n",
    "\n",
    "# plot\n",
    "# ----\n",
    "\n",
    "display(Markdown(\"## Plotting payoff \" + payoff_def.name))\n",
    "from deephedging.base import npCast, mean_bins\n",
    "from cdxbasics.dynaplot import figure, colors_base\n",
    "import numpy as np\n",
    "\n",
    "payoff = world.data.market.payoff\n",
    "spots  = world.details.spot_all\n",
    "notko  = world.data.features.per_step.payoff_features\n",
    "ref    = spots[:,-1]\n",
    "ixs    = np.argsort(ref)\n",
    "nko_s  = notko[ixs,-1]\n",
    "ref_s  = ref[ixs]\n",
    "pyo_s  = payoff[ixs]\n",
    "colors = colors_base()\n",
    "\n",
    "fig = figure(col_size=10,col_nums=1)\n",
    "ax = fig.add_subplot()\n",
    "ax.set_title(\"%s\" % payoff_def.name)\n",
    "\n",
    "xm   = mean_bins( ref_s, bins=nBins, weights=world.sample_weights, return_std = False )\n",
    "m, s = mean_bins( pyo_s, bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "col  = next(colors)\n",
    "ax.plot( xm, m, color=col, label=\"payoff\")\n",
    "ax.fill_between( xm, m-s,m+s, color=col,alpha=0.2)\n",
    "\n",
    "xm   = mean_bins( ref_s[nko_s > 0.], bins=nBins, weights=world.sample_weights, return_std = False )\n",
    "m, s = mean_bins( pyo_s[nko_s > 0.], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "col  = next(colors)\n",
    "ax.plot( xm, m, color=col, label=\"not KO'd\")\n",
    "ax.fill_between( xm, m-s,m+s, color=col,alpha=0.2)\n",
    "\n",
    "xm   = mean_bins( ref_s[nko_s < 1.], bins=nBins, weights=world.sample_weights, return_std = False )\n",
    "m, s = mean_bins( pyo_s[nko_s < 1.], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "col  = next(colors)\n",
    "ax.plot( xm, m, color=col, label=\"has KO'd\")\n",
    "ax.fill_between( xm, m-s,m+s, color=col,alpha=0.2)\n",
    "\n",
    "ax.legend()\n",
    "fig.close()\n",
    "\n",
    "# Create test configs\n",
    "# -------------------\n",
    "\n",
    "configs = pdct()\n",
    "\n",
    "# not recurrent\n",
    "config = config_ref.copy()\n",
    "config.gym.agent.recurrence.states.classic   = 0\n",
    "config.gym.agent.recurrence.states.aggregate = 0\n",
    "config.gym.agent.recurrence.states.past_repr = 0\n",
    "config.gym.agent.recurrence.states.event     = 0\n",
    "config.world.mark_done()\n",
    "configs.none = config\n",
    "\n",
    "# digital states\n",
    "config = config_ref.copy()\n",
    "config.gym.agent.recurrence.states.classic   = 0\n",
    "config.gym.agent.recurrence.states.aggregate = 0\n",
    "config.gym.agent.recurrence.states.past_repr = 5\n",
    "config.gym.agent.recurrence.states.event     = 5\n",
    "config.world.mark_done()\n",
    "configs.digital = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb79f6-f944-4ff1-afde-43484a8f94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# ----\n",
    "results = pdct()\n",
    "\n",
    "for k in configs:\n",
    "    config = configs[k]\n",
    "    display(Markdown(\"## Hedging a %s in recurrent '%s' mode\" % (payoff_def.name, k)))\n",
    "    gym = VanillaDeepHedgingGym( config.gym )\n",
    "    train( gym=gym, world=world, val_world=val_world, config=config.trainer )\n",
    "    results[k] = npCast( gym(world.tf_data) )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228de7e1-dd06-4f49-8df2-e775a3fca184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephedging.base import npCast, mean_bins\n",
    "from deephedging.fd import bs_fd\n",
    "from deephedging.objectives import MonetaryUtility\n",
    "from cdxbasics.dynaplot import figure, colors_base\n",
    "from scipy.stats import norm\n",
    "import math as math\n",
    "import numpy as np\n",
    "\n",
    "spots      = world.details.spot_all\n",
    "hedges     = world.data.market.hedges[:,:,0]\n",
    "time_left  = world.data.features.per_step.time_left[0,:]\n",
    "nSteps     = world.nSteps\n",
    "nSamples   = world.nSamples\n",
    "nBins      = 200\n",
    "nBinSteps  = 7\n",
    "fdstd      = 5.\n",
    "fdgrid     = 501\n",
    "times      = world.timeline\n",
    "ixs        = np.linspace(0,nSteps,nBinSteps,endpoint=True,dtype=np.int32)\n",
    "vol        = config.world.get_raw(\"rvol\", 0.2)\n",
    "\n",
    "# collect actions\n",
    "actions = { k: results[k]['actions'][:,:,0] for k in results }\n",
    "deltas  = { k: np.cumsum( actions[k], axis=1) for k in results }\n",
    "pnls    = { k: np.zeros((nSamples,)) for k in results }\n",
    "pnls['blackscholes'] = np.zeros((nSamples,))\n",
    "prev_deltas_t  = { k: 0. for k in pnls }\n",
    "\n",
    "keys_sorted = ['blackscholes'] + list( results.keys() )\n",
    "\n",
    "# FD pricer\n",
    "# ---------\n",
    "def fd_payoff( X, F, t ):\n",
    "    F     = - np.maximum( strike - X, 0.) if F is None else F\n",
    "    return np.where( X > barrier, F, 0. )\n",
    "fd_spots = np.exp( np.linspace(-fdstd,+fdstd,1+2*(fdgrid//2),endpoint=True) * vol * times[-1] )\n",
    "fd = bs_fd( spots=[fd_spots]*(nSteps+1), times=times, payoff=fd_payoff, vol=vol, cn_factor='implicit')\n",
    "\n",
    "# plot hedging\n",
    "# ------------\n",
    "\n",
    "display(Markdown(\"## %s Hedging\" % payoff_def.name))\n",
    "fig = figure()\n",
    "\n",
    "for j in range(nSteps):\n",
    "    ax_delta  = fig.add_subplot()\n",
    "   # ax_delta.set_ylim(-1.1,0.1)\n",
    "\n",
    "    # sort by spot at j, and compute BS refernece\n",
    "    spot_t    = spots[:,j]\n",
    "    hedges_t  = hedges[:,j]   # S(T)-S(t_j)\n",
    "    res_t     = time_left[j]\n",
    "    dt        = times[j+1] - times[j]\n",
    "    \n",
    "    deltas_t  = { k: deltas[k][:,j] for k in deltas }\n",
    "    deltas_t['blackscholes'] \\\n",
    "              = fd[j].bump_delta( spot_t, vol * math.sqrt(dt) )\n",
    "    pnls      = { k: pnls[k] + deltas_t[k] * hedges_t for k in pnls }\n",
    "\n",
    "    # plot\n",
    "    ixs       = np.argsort(spot_t)\n",
    "    spot_t    = spot_t[ixs]\n",
    "    deltas_t  = { k: deltas_t[k][ixs] for k in deltas_t }\n",
    "    \n",
    "    x_mean    = mean_bins( spot_t, bins=nBins, weights=world.sample_weights, return_std = False )\n",
    "    colors    = colors_base()\n",
    "    for k in keys_sorted:\n",
    "        mean, std = mean_bins( deltas_t[k], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "        color     = next(colors)\n",
    "        ax_delta.plot( x_mean, mean, label=k, color=color)\n",
    "        ax_delta.fill_between( x_mean, mean-std, mean+std, color=color, alpha=0.1 )\n",
    "\n",
    "    ax_delta.legend()\n",
    "    \n",
    "fig.render()\n",
    "fig.close()\n",
    "\n",
    "# terminal\n",
    "# --------\n",
    "\n",
    "display(Markdown(\"## Terminal %s Profiles\" % payoff_def.name))\n",
    "\n",
    "spots    = world.details.spot_all\n",
    "payoff   = world.data.market.payoff\n",
    "notko    = world.data.features.per_step.payoff_features[:,-1]\n",
    "payoff   = payoff - np.mean( payoff )\n",
    "\n",
    "spot_ret = spots[:,-1]\n",
    "ixs      = np.argsort(spot_ret)\n",
    "spot_ret = spot_ret[ixs]\n",
    "pnls     = { k : pnls[k][ixs] for k in pnls }\n",
    "payoff   = payoff[ixs]\n",
    "notko    = notko[ixs]\n",
    "\n",
    "# basic\n",
    "spot_mean = mean_bins( spot_ret, bins=nBins, weights=world.sample_weights, return_std = False )\n",
    "payoff_mean, payoff_std = mean_bins( payoff, bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "\n",
    "fig = figure(col_size=10,col_nums=1)\n",
    "ax = fig.add_subplot()\n",
    "ax.set_title(\"Terminal Payoff\")\n",
    "ax.set_xlabel(\"Spot\")\n",
    "\n",
    "colors = colors_base()\n",
    "color  = next(colors)\n",
    "ax.plot( spot_mean, -payoff_mean, label=\"-payoff\", color=color)\n",
    "ax.fill_between( spot_mean, -payoff_mean-payoff_std, -payoff_mean+payoff_std , color=color, alpha=0.1 )\n",
    "_min = np.min(-payoff_mean-payoff_std)\n",
    "_max = np.max(-payoff_mean+payoff_std)\n",
    "for k in keys_sorted:\n",
    "    color = next(colors)\n",
    "    mean, std = mean_bins( pnls[k], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "\n",
    "    ax.plot( spot_mean, mean, label=k, color=color )\n",
    "    ax.fill_between( spot_mean, mean-std, mean+std, color=color, alpha=0.1 )\n",
    "    _min = min(np.min(mean),_min)\n",
    "    _max = max(np.max(mean),_max)\n",
    "\n",
    "ax.legend()\n",
    "dm = max(_max - _min, 0.001)\n",
    "_max == dm*0.005\n",
    "_min -= dm*0.005\n",
    "ax.set_ylim(_min,_max)\n",
    "fig.render()\n",
    "fig.close()\n",
    "\n",
    "# not KO'd\n",
    "print(spot_ret.shape, notko.shape)\n",
    "spot_mean = mean_bins( spot_ret[notko > 0.], bins=nBins, weights=world.sample_weights, return_std = False )\n",
    "payoff_mean, payoff_std = mean_bins( payoff[notko > 0.], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "\n",
    "fig = figure(col_size=10,col_nums=1)\n",
    "ax = fig.add_subplot()\n",
    "ax.set_title(\"Terminal Payoff\\nNot KO'd\")\n",
    "ax.set_xlabel(\"Spot\")\n",
    "\n",
    "colors = colors_base()\n",
    "color  = next(colors)\n",
    "ax.plot( spot_mean, -payoff_mean, label=\"-payoff\", color=color)\n",
    "ax.fill_between( spot_mean, -payoff_mean-payoff_std, -payoff_mean+payoff_std , color=color, alpha=0.1 )\n",
    "for k in keys_sorted:\n",
    "    color = next(colors)\n",
    "    mean, std = mean_bins( pnls[k][notko > 0.], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "\n",
    "    ax.plot( spot_mean, mean, label=k, color=color )\n",
    "    ax.fill_between( spot_mean, mean-std, mean+std, color=color, alpha=0.1 )\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(_min,_max)\n",
    "fig.render()\n",
    "fig.close()\n",
    "\n",
    "# KO'd\n",
    "spot_mean = mean_bins( spot_ret[notko < 1.], bins=nBins, weights=world.sample_weights, return_std = False )\n",
    "payoff_mean, payoff_std = mean_bins( payoff[notko < 1.], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "\n",
    "fig = figure(col_size=10,col_nums=1)\n",
    "ax = fig.add_subplot()\n",
    "ax.set_title(\"Terminal Payoff\\nKO'd\")\n",
    "ax.set_xlabel(\"Spot\")\n",
    "\n",
    "colors = colors_base()\n",
    "color  = next(colors)\n",
    "ax.plot( spot_mean, -payoff_mean, label=\"-payoff\", color=color)\n",
    "ax.fill_between( spot_mean, -payoff_mean-payoff_std, -payoff_mean+payoff_std , color=color, alpha=0.1 )\n",
    "for k in keys_sorted:\n",
    "    color = next(colors)\n",
    "    mean, std = mean_bins( pnls[k][notko < 1.], bins=nBins, weights=world.sample_weights, return_std = True )\n",
    "\n",
    "    ax.plot( spot_mean, mean, label=k, color=color )\n",
    "    ax.fill_between( spot_mean, mean-std, mean+std, color=color, alpha=0.1 )\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(_min,_max)\n",
    "fig.render()\n",
    "fig.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4df09d-b118-4e03-a21a-7ef8a3944ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephedging.objectives import oce_utility\n",
    "from cdxbasics.dynaplot import figure, colors_tableau\n",
    "\n",
    "display(Markdown(\"## Utilities for %s\" % payoff_def.name))\n",
    "\n",
    "utilities = ['cvar', 'exp2', 'exp', 'vicky', 'quad' ]\n",
    "lambdas  = np.exp(np.linspace( -2.,2., 21, endpoint=True) )\n",
    "\n",
    "fig = figure()\n",
    "axs = dict()\n",
    "for util in utilities:\n",
    "    ax  = fig.add_subplot()\n",
    "    ax.set_title(util)\n",
    "    ax.set_xlabel(\"Log-Lambda\")\n",
    "    axs[util] = ax\n",
    "fig.render()\n",
    "\n",
    "\n",
    "for util in utilities:\n",
    "    ax  = axs[util]\n",
    "    \n",
    "    colors = colors_tableau()\n",
    "    \n",
    "    for k in pnls:\n",
    "        pnl = pnls[k]\n",
    "        us  = [ oce_utility(util, lmnda, pnl ) for lmnda in lambdas ]\n",
    "\n",
    "        ax.plot( np.log(lambdas), us, next(colors), label=k )\n",
    "\n",
    "    ax.legend()\n",
    "    fig.render()\n",
    "    \n",
    "fig.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fe7bd-4191-433b-99d5-f59f679ec324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.usage_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a7510-4c20-42f9-819c-d82bbe6e6041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
