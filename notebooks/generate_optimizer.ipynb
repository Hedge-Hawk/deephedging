{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2952cfd0-5083-4ac6-afa1-6a4aaadd8cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'keras.Optimizer': <Signature (self, name, gradient_aggregator=None, gradient_transformers=None, **kwargs)>, 'keras.Adam': <Signature (learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam', **kwargs)>}\n",
      "{'gradient_aggregator': <Parameter \"gradient_aggregator=None\">, 'gradient_transformers': <Parameter \"gradient_transformers=None\">, 'learning_rate': 0.01, 'beta_1': <Parameter \"beta_1=0.9\">, 'beta_2': <Parameter \"beta_2=0.999\">, 'epsilon': <Parameter \"epsilon=1e-07\">, 'amsgrad': <Parameter \"amsgrad=False\">}\n",
      "<keras.optimizers.optimizer_v2.adam.Adam object at 0x7fbb39c46050>\n",
      "{'class_name': 'Adam', 'config': {'name': 'Adam', 'learning_rate': 0.01, 'decay': 0.0, 'beta_1': <Parameter \"beta_1=0.9\">, 'beta_2': <Parameter \"beta_2=0.999\">, 'epsilon': <Parameter \"epsilon=1e-07\">, 'amsgrad': <Parameter \"amsgrad=False\">}}\n",
      "config['clipnorm'] = 1.0\n",
      "config['learning_rate'] = 0.01\n",
      "config['name'] = adam\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import inspect\n",
    "from cdxbasics.config import Config\n",
    "\n",
    "def create_optimizer( config : Config = Config() ):\n",
    "    \"\"\"\n",
    "    Creates an optimizer from a config object\n",
    "    \"\"\"\n",
    "    \n",
    "    name      = config(\"name\", \"adam\", str, \"Optimizer name. See https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\")\n",
    "    optimizer = tf.keras.optimizers.get(name)\n",
    "    sig_opt   = inspect.signature(optimizer.__init__)\n",
    "    sig_bse   = inspect.signature(tf.keras.optimizers.Optimizer.__init__)\n",
    "    kwargs    = {}\n",
    "    \n",
    "    sigs = { \"keras.Optimizer\": sig_bse,\n",
    "             \"keras.\" + adam.__class__.__name__: sig_opt} \n",
    "\n",
    "    print(sigs)\n",
    "    for opt in sigs:\n",
    "        sig = sigs[opt]\n",
    "        for para in sig.parameters:\n",
    "            if para in ['self','name','kwargs']:\n",
    "                continue\n",
    "\n",
    "            default = sig.parameters[para]\n",
    "            if default == inspect.Parameter.empty:\n",
    "                # mandatory parameter\n",
    "                kwargs[para] = config(para, help=\"Parameter %s for %s\" % (para,opt))\n",
    "            else:\n",
    "                # optional parameter\n",
    "                kwargs[para] = config(para, default, help=\"Parameter %s for %s\" % (para,opt))\n",
    "\n",
    "    print(kwargs)    \n",
    "    return optimizer.__class__(**kwargs)\n",
    "                \n",
    "config = Config()\n",
    "config.name = \"adam\"\n",
    "config.clipnorm = 1.\n",
    "config.learning_rate = 0.01\n",
    "    \n",
    "optimizer = create_optimizer(config)\n",
    "print(optimizer)\n",
    "print(tf.keras.optimizers.serialize(optimizer))\n",
    "print(config.input_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54afe03c-b19f-4f0c-8638-9e14a864bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam()\n",
    "print(adam.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09c3496c-145c-4146-8098-2184e4ace9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'inspect.Signature'> (self, learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam', **kwargs) OrderedDict([('self', <Parameter \"self\">), ('learning_rate', <Parameter \"learning_rate=0.001\">), ('beta_1', <Parameter \"beta_1=0.9\">), ('beta_2', <Parameter \"beta_2=0.999\">), ('epsilon', <Parameter \"epsilon=1e-07\">), ('amsgrad', <Parameter \"amsgrad=False\">), ('name', <Parameter \"name='Adam'\">), ('kwargs', <Parameter \"**kwargs\">)])\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "x = inspect.signature(adam.__init__)\n",
    "print(type(x),x,x.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb951f4-7419-466b-98ba-3aa2e196bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self <class 'inspect._empty'>\n",
      "learning_rate 0.001\n",
      "beta_1 0.9\n",
      "beta_2 0.999\n",
      "epsilon 1e-07\n",
      "amsgrad False\n",
      "name Adam\n",
      "kwargs <class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "for k in x.parameters:\n",
    "    print(k,x.parameters[k].default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728fc92f-62a4-458b-878b-6572513bd265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
